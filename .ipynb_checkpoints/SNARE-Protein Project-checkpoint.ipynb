{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNARE-Protein Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Any Known Proteins From SNARE Family Belongs to Mycobacterium Tuberculosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get SNARE family protein IDs from InterPro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloadProteinID function \n",
    "# input: \n",
    "#   None\n",
    "# output:\n",
    "#   the name of the file contains a list of proteins IDs downloaded from InterPro\n",
    "def downloadProteinID ():\n",
    "    url = \"http://www.ebi.ac.uk/interpro/entry/IPR010989/proteins-matched?taxonomy=2&export=ids\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(\"SNARE_proteins_bacteria.txt\", 'wb').write(r.content)\n",
    "    return \"SNARE_proteins_bacteria.txt\"\n",
    "\n",
    "# The file of protein ids download from InterPro\n",
    "proteinIDs = downloadProteinID ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get organism names from Uniport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchUniport_stable function\n",
    "# input:\n",
    "#   filename: string\n",
    "#             the filename of a list of Protein ids \n",
    "# output:\n",
    "#   a file with all the organism names matched to the protein ids and the\n",
    "#   corresponding freqency of apperance\n",
    "# SideNote: This function accomplish the smae goal as searchUniport_fast, but\n",
    "#           this function accomplish the goal with uniprot api, where the \n",
    "#           result is stable but rather slow, which could take up to 10 mins.\n",
    "def searchUniport_stable (filename):\n",
    "    outFile = open(\"organism.txt\", \"w\")\n",
    "    proteinIDs = open(filename, \"r\")\n",
    "    orgDic = {}\n",
    "    for protein in proteinIDs:\n",
    "        url = \"https://www.uniprot.org/uniprot/?query=id:\" + protein + \"&columns=organism&format=tab\"\n",
    "        print(\"before\")\n",
    "        result = requests.get(url).content\n",
    "        print (\"after\")\n",
    "        organism = str(result).split(\"\\\\n\")[1]\n",
    "        if organism in orgDic:\n",
    "            orgDic[organism] = orgDic[organism] + 1\n",
    "        else:\n",
    "            orgDic[organism] = 1\n",
    "    for org_freqs in sorted(orgDic, key=orgDic.get, reverse=True):\n",
    "        outFile.write(str(orgDic[org_freqs]) + \" \" + org_freqs + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchUniport_fast function\n",
    "# input:\n",
    "#   filename: string\n",
    "#             the filename of a list of Protein ids \n",
    "# output:\n",
    "#   a file with all the organism names matched to the protein ids and the\n",
    "#   corresponding freqency of apperance\n",
    "# SideNote: This function accomplish the smae goal as searchUniport_stable, but\n",
    "#           accomplish the goal with python's BeautifulSoup package, where the \n",
    "#           result could be unstable but faster than using Uniport API. \n",
    "def searchUniport_fast (filename):\n",
    "    outFile = open(\"organism.txt\", \"w\")\n",
    "    proteinIDs = open(filename, \"r\")\n",
    "    orgDic = {}\n",
    "    for protein in proteinIDs:\n",
    "        text = requests.get('http://www.uniprot.org/uniprot/' + protein).text\n",
    "        soup = BS(text)\n",
    "        title = soup.head.title.text\n",
    "        organism = title.split(\" - \")[2]\n",
    "        if organism in orgDic:\n",
    "            orgDic[organism] = orgDic[organism] + 1\n",
    "        else:\n",
    "            orgDic[organism] = 1\n",
    "    for org_freqs in sorted(orgDic, key=orgDic.get, reverse=True):\n",
    "        outFile.write(str(orgDic[org_freqs]) + \" \" + org_freqs + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get organism names from Uniport. This could take a while depends on the function choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchUniport_fast(proteinIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Search through the organism names to see if it contains Mycobacterium Tuberculosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryOrg function\n",
    "# input: \n",
    "#   queryName: string\n",
    "#              the name of organism we want check if it's in the organism list\n",
    "#   orgFile: string\n",
    "#            the name of the file output by searchUniport function, which contains\n",
    "#            all the organism names that have a specific protein fanmily\n",
    "# output:\n",
    "#   a boolean that tells if the query organism is in the organisms list\n",
    "def queryOrg (queryName, orgFile):\n",
    "    f = open(orgFile, \"r\")\n",
    "    for org in f:\n",
    "        lowerOrg = org.lower()\n",
    "        qLower = queryName.lower()\n",
    "        if qLower in lowerOrg:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mycobacterium tuberculosis is in the name list: False\n"
     ]
    }
   ],
   "source": [
    "# Determine if TB is in the orgnanism list\n",
    "query = \"Mycobacterium tuberculosis\"\n",
    "organism = \"organism.txt\"\n",
    "result = queryOrg(query, organism)\n",
    "print (\"Mycobacterium tuberculosis is in the name list: \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blast SNARE-like proteins against Mycobacterium tuberculosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a list of all (most) predicted \"Incs\" from C. trachomatis from the paper *Expression and Localization of Predicted Inclusion Membrane Proteins in Chlamydia trachomatis, Mary M. Weber ect.* Store the tags and 3 corresponding strains in **C.trachomatis_predict_Incs.txt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the locus tag for D/UW-3/CX strain in order to match NCBI locus tag format and store the changed tags into DUW-3CX_predict_Incs.txt file using unix command:\n",
    "```shell\n",
    "cut -d \" \" -f 1 C.trachomatis_predict_Incs.txt | sed s/CT/CT_/g > DUW-3CX_predict_Incs.txt\n",
    "```\n",
    "Get the locus tag for L2/434/Bu strain and A/HAR-13 strain using similar commands:\n",
    "```shell\n",
    "cut -d \" \" -f 2 C.trachomatis_predict_Incs.txt > L2434Bu_predict_Incs.txt\n",
    "cut -d \" \" -f 3 C.trachomatis_predict_Incs.txt > AHAR13_predict_Incs.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import protein tags for each strains as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  D/UW-3/CX\n",
      "0    CT_005\n",
      "1    CT_006\n",
      "2    CT_036\n",
      "3    CT_058\n",
      "4    CT_079\n",
      "  L2/434/Bu\n",
      "0   CTL0260\n",
      "1   CTL0261\n",
      "2   CTL0291\n",
      "3   CTL0314\n",
      "4   CTL0335\n",
      "  A/HAR-13\n",
      "0  CTA0006\n",
      "1  CTA0007\n",
      "2  CTA0038\n",
      "3  CTA0062\n",
      "4  CTA0084\n"
     ]
    }
   ],
   "source": [
    "DUW3CX_proteins = pd.read_csv(\"DUW-3CX_predict_Incs.txt\", sep = \" \", index_col = False)\n",
    "L2434Bu_proteins = pd.read_csv(\"L2434Bu_predict_Incs.txt\", sep = \" \", index_col = False)\n",
    "AHAR13_proteins = pd.read_csv(\"AHAR13_predict_Incs.txt\", sep = \" \", index_col = False)\n",
    "\n",
    "print(DUW3CX_proteins.head())\n",
    "print(L2434Bu_proteins.head())\n",
    "print(AHAR13_proteins.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up Entrez Direct to perfrom BLAST search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the direction from NCBI website [here](https://www.ncbi.nlm.nih.gov/books/NBK179288/), install Entrez Direct: E-utilities on the UNIX Command Line.\n",
    "\n",
    "First, run the following code on terminal:\n",
    "```shell\n",
    "cd ~\n",
    "  /bin/bash\n",
    "  perl -MNet::FTP -e \\\n",
    "    '$ftp = new Net::FTP(\"ftp.ncbi.nlm.nih.gov\", Passive => 1);\n",
    "     $ftp->login; $ftp->binary;\n",
    "     $ftp->get(\"/entrez/entrezdirect/edirect.tar.gz\");'\n",
    "  gunzip -c edirect.tar.gz | tar xf -\n",
    "  rm edirect.tar.gz\n",
    "  builtin exit\n",
    "  export PATH=${PATH}:$HOME/edirect >& /dev/null || setenv PATH \"${PATH}:$HOME/edirect\"\n",
    "  ./edirect/setup.sh\n",
    "```\n",
    "Then, add the command edirect to soucre.sh so that it can be run in any path:\n",
    "\n",
    "```shell\n",
    "echo \"source ~/.bash_profile\" >> $HOME/.bashrc\n",
    "echo \"export PATH=\\${PATH}:/Users/xuqiantan/edirect\" >> $HOME/.bash_profile\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use esearch to get the sequence of the tagged locus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the unix command below to get tagged locus protein sequences for each strain and store all the sequence in **Chlamydia_protein_seq.fasta** for blast search:\n",
    "\n",
    "```shell\n",
    "for file in DUW-3CX_predict_Incs.txt L2434Bu_predict_Incs.txt AHAR13_predict_Incs.txt\n",
    "do\n",
    "    input=${file}\n",
    "    while read line\n",
    "    do\n",
    "        echo ${line}\n",
    "        esearch -db protein -query ${line} | efetch -format fasta >> Chlamydia_protein_seq.fasta\n",
    "    done < ${file}\n",
    "done\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform blast search on the protein sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
